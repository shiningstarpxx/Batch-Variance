#!/usr/bin/env python3
"""
åˆ†æä¸ºä»€ä¹ˆBatch-invariantæ–¹æ³•ä»ç„¶æœ‰å·®å¼‚

æ·±å…¥åˆ†ææµ®ç‚¹æ•°è¿ç®—çš„ç»†å¾®å·®å¼‚æ¥æº
"""

import torch
import numpy as np
import matplotlib.pyplot as plt

# å¯¼å…¥å­—ä½“é…ç½®
try:
    from src.font_config import setup_chinese_fonts
except ImportError:
    from font_config import setup_chinese_fonts

setup_chinese_fonts()

class InvariantDifferenceAnalyzer:
    """åˆ†æBatch-invariantå·®å¼‚çš„ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        self.device = torch.device('cpu')  # ä½¿ç”¨CPUç¡®ä¿ç²¾ç¡®æ€§
    
    def analyze_floating_point_precision(self):
        """åˆ†ææµ®ç‚¹æ•°ç²¾åº¦é—®é¢˜"""
        print("=== æµ®ç‚¹æ•°ç²¾åº¦åˆ†æ ===\n")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        torch.manual_seed(42)
        x = torch.randn(2, 4, 8, device=self.device)
        
        print("ğŸ“Š æµ‹è¯•æ•°æ®:")
        print(f"è¾“å…¥å½¢çŠ¶: {x.shape}")
        print(f"è¾“å…¥æ•°æ®ç±»å‹: {x.dtype}")
        print(f"è¾“å…¥å‰å‡ ä¸ªå€¼: {x[0, 0, :4]}")
        print()
        
        # æ–¹æ³•1: æ ‡å‡†RMSNorm (ä½¿ç”¨torch.mean)
        std_rms = torch.sqrt(torch.mean(x ** 2, dim=-1, keepdim=True) + 1e-6)
        std_output = x / std_rms
        
        # æ–¹æ³•2: æ‰‹åŠ¨è®¡ç®—RMS (é€å…ƒç´ )
        manual_rms_squared = torch.zeros_like(std_rms)
        for i in range(x.shape[-1]):
            manual_rms_squared += x[:, :, i:i+1] ** 2
        manual_rms = torch.sqrt(manual_rms_squared / x.shape[-1] + 1e-6)
        manual_output = x / manual_rms
        
        # æ–¹æ³•3: ä½¿ç”¨torch.sumç„¶åé™¤ä»¥é•¿åº¦
        sum_rms_squared = torch.sum(x ** 2, dim=-1, keepdim=True)
        sum_rms = torch.sqrt(sum_rms_squared / x.shape[-1] + 1e-6)
        sum_output = x / sum_rms
        
        # è®¡ç®—å·®å¼‚
        std_manual_diff = torch.max(torch.abs(std_output - manual_output)).item()
        std_sum_diff = torch.max(torch.abs(std_output - sum_output)).item()
        manual_sum_diff = torch.max(torch.abs(manual_output - sum_output)).item()
        
        print("ğŸ” å·®å¼‚åˆ†æ:")
        print(f"æ ‡å‡†RMSNorm vs æ‰‹åŠ¨è®¡ç®—: {std_manual_diff:.2e}")
        print(f"æ ‡å‡†RMSNorm vs torch.sum: {std_sum_diff:.2e}")
        print(f"æ‰‹åŠ¨è®¡ç®— vs torch.sum: {manual_sum_diff:.2e}")
        print()
        
        print("ğŸ“ˆ è¯¦ç»†æ•°å€¼å¯¹æ¯” (ç¬¬ä¸€ä¸ªæ ·æœ¬å‰4ä¸ªå€¼):")
        print(f"æ ‡å‡†RMSNorm:     {std_output[0, 0, :4].numpy()}")
        print(f"æ‰‹åŠ¨è®¡ç®—:        {manual_output[0, 0, :4].numpy()}")
        print(f"torch.sum:       {sum_output[0, 0, :4].numpy()}")
        print()
        
        return {
            'std_output': std_output,
            'manual_output': manual_output,
            'sum_output': sum_output,
            'std_manual_diff': std_manual_diff,
            'std_sum_diff': std_sum_diff,
            'manual_sum_diff': manual_sum_diff
        }
    
    def analyze_accumulation_order(self):
        """åˆ†æç´¯ç§¯é¡ºåºçš„å½±å“"""
        print("=== ç´¯ç§¯é¡ºåºå½±å“åˆ†æ ===\n")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        torch.manual_seed(42)
        x = torch.randn(2, 4, 8, device=self.device)
        
        # æ–¹æ³•1: é¡ºåºç´¯ç§¯
        sequential_sum = torch.zeros(2, 4, 1, device=self.device)
        for i in range(x.shape[-1]):
            sequential_sum += x[:, :, i:i+1] ** 2
        
        # æ–¹æ³•2: ä¸¤ä¸¤ç´¯ç§¯
        pairwise_sum = torch.zeros(2, 4, 1, device=self.device)
        for i in range(0, x.shape[-1], 2):
            if i + 1 < x.shape[-1]:
                pairwise_sum += x[:, :, i:i+1] ** 2 + x[:, :, i+1:i+2] ** 2
            else:
                pairwise_sum += x[:, :, i:i+1] ** 2
        
        # æ–¹æ³•3: å››å››ç´¯ç§¯
        chunk_sum = torch.zeros(2, 4, 1, device=self.device)
        for i in range(0, x.shape[-1], 4):
            end_idx = min(i + 4, x.shape[-1])
            chunk_sum += torch.sum(x[:, :, i:end_idx] ** 2, dim=-1, keepdim=True)
        
        # è®¡ç®—å·®å¼‚
        seq_pair_diff = torch.max(torch.abs(sequential_sum - pairwise_sum)).item()
        seq_chunk_diff = torch.max(torch.abs(sequential_sum - chunk_sum)).item()
        pair_chunk_diff = torch.max(torch.abs(pairwise_sum - chunk_sum)).item()
        
        print("ğŸ” ç´¯ç§¯é¡ºåºå·®å¼‚:")
        print(f"é¡ºåº vs ä¸¤ä¸¤: {seq_pair_diff:.2e}")
        print(f"é¡ºåº vs åˆ†å—: {seq_chunk_diff:.2e}")
        print(f"ä¸¤ä¸¤ vs åˆ†å—: {pair_chunk_diff:.2e}")
        print()
        
        print("ğŸ“ˆ ç´¯ç§¯ç»“æœå¯¹æ¯”:")
        print(f"é¡ºåºç´¯ç§¯: {sequential_sum[0, 0, 0].item():.10f}")
        print(f"ä¸¤ä¸¤ç´¯ç§¯: {pairwise_sum[0, 0, 0].item():.10f}")
        print(f"åˆ†å—ç´¯ç§¯: {chunk_sum[0, 0, 0].item():.10f}")
        print()
        
        return {
            'sequential_sum': sequential_sum,
            'pairwise_sum': pairwise_sum,
            'chunk_sum': chunk_sum,
            'seq_pair_diff': seq_pair_diff,
            'seq_chunk_diff': seq_chunk_diff,
            'pair_chunk_diff': pair_chunk_diff
        }
    
    def analyze_eps_effect(self):
        """åˆ†æepså‚æ•°çš„å½±å“"""
        print("=== epså‚æ•°å½±å“åˆ†æ ===\n")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        torch.manual_seed(42)
        x = torch.randn(2, 4, 8, device=self.device)
        
        eps_values = [1e-6, 1e-7, 1e-8, 1e-9, 0]
        results = {}
        
        for eps in eps_values:
            rms = torch.sqrt(torch.mean(x ** 2, dim=-1, keepdim=True) + eps)
            output = x / rms
            results[eps] = output
        
        print("ğŸ” epså‚æ•°å¯¹ç»“æœçš„å½±å“:")
        base_output = results[1e-6]
        for eps, output in results.items():
            diff = torch.max(torch.abs(base_output - output)).item()
            print(f"eps={eps}: å·®å¼‚ {diff:.2e}")
        print()
        
        return results
    
    def analyze_device_differences(self):
        """åˆ†æä¸åŒè®¾å¤‡çš„å·®å¼‚"""
        print("=== è®¾å¤‡å·®å¼‚åˆ†æ ===\n")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        torch.manual_seed(42)
        x_cpu = torch.randn(2, 4, 8, device='cpu')
        
        # CPUç»“æœ
        cpu_rms = torch.sqrt(torch.mean(x_cpu ** 2, dim=-1, keepdim=True) + 1e-6)
        cpu_output = x_cpu / cpu_rms
        
        # MPSç»“æœ (å¦‚æœå¯ç”¨)
        if torch.backends.mps.is_available():
            x_mps = x_cpu.to('mps')
            mps_rms = torch.sqrt(torch.mean(x_mps ** 2, dim=-1, keepdim=True) + 1e-6)
            mps_output = x_mps / mps_rms
            mps_output_cpu = mps_output.cpu()
            
            diff = torch.max(torch.abs(cpu_output - mps_output_cpu)).item()
            print(f"CPU vs MPSå·®å¼‚: {diff:.2e}")
            
            print("ğŸ“ˆ è®¾å¤‡ç»“æœå¯¹æ¯” (ç¬¬ä¸€ä¸ªæ ·æœ¬å‰4ä¸ªå€¼):")
            print(f"CPU: {cpu_output[0, 0, :4].numpy()}")
            print(f"MPS: {mps_output_cpu[0, 0, :4].numpy()}")
        else:
            print("MPSä¸å¯ç”¨ï¼Œè·³è¿‡è®¾å¤‡å¯¹æ¯”")
        
        print()
    
    def explain_why_differences_exist(self):
        """è§£é‡Šä¸ºä»€ä¹ˆå­˜åœ¨å·®å¼‚"""
        print("=== ä¸ºä»€ä¹ˆBatch-invariantä»ç„¶æœ‰å·®å¼‚ï¼Ÿ ===\n")
        
        print("ğŸ” ä¸»è¦åŸå› :")
        print("1. **æµ®ç‚¹æ•°ç²¾åº¦é™åˆ¶**: å³ä½¿ä½¿ç”¨ç›¸åŒçš„ç®—æ³•ï¼Œæµ®ç‚¹æ•°è¿ç®—ä»æœ‰ç²¾åº¦é™åˆ¶")
        print("2. **ç´¯ç§¯é¡ºåºå·®å¼‚**: ä¸åŒçš„ç´¯ç§¯é¡ºåºå¯¼è‡´ä¸åŒçš„èˆå…¥è¯¯å·®")
        print("3. **å®ç°æ–¹å¼å·®å¼‚**: torch.mean vs æ‰‹åŠ¨ç´¯ç§¯çš„å®ç°æ–¹å¼ä¸åŒ")
        print("4. **è®¾å¤‡å·®å¼‚**: CPUå’ŒGPUçš„æµ®ç‚¹æ•°è¿ç®—å¯èƒ½æœ‰å¾®å°å·®å¼‚")
        print("5. **ç¼–è¯‘å™¨ä¼˜åŒ–**: ä¸åŒçš„ä¼˜åŒ–çº§åˆ«å¯èƒ½äº§ç”Ÿä¸åŒçš„ç»“æœ")
        print()
        
        print("ğŸ’¡ å…³é”®æ´å¯Ÿ:")
        print("â€¢ Batch-invariantçš„ç›®æ ‡ä¸æ˜¯æ¶ˆé™¤æ‰€æœ‰å·®å¼‚")
        print("â€¢ è€Œæ˜¯ç¡®ä¿ç›¸åŒè¾“å…¥åœ¨ä¸åŒæ‰¹å¤„ç†å¤§å°ä¸‹äº§ç”Ÿç›¸åŒç»“æœ")
        print("â€¢ å¾®å°çš„æ•°å€¼å·®å¼‚ (1e-6çº§åˆ«) æ˜¯å¯ä»¥æ¥å—çš„")
        print("â€¢ é‡è¦çš„æ˜¯æ¶ˆé™¤éç¡®å®šæ€§çš„å·®å¼‚ (1e-3çº§åˆ«)")
        print()
        
        print("ğŸ¯ å®é™…æ„ä¹‰:")
        print("â€¢ 1e-6çº§åˆ«çš„å·®å¼‚å¯¹æ¨¡å‹æ€§èƒ½å½±å“æå°")
        print("â€¢ ä½†ç¡®ä¿äº†æ¨ç†çš„ç¡®å®šæ€§å’Œå¯é‡ç°æ€§")
        print("â€¢ è¿™æ˜¯ç§‘å­¦è®¡ç®—ä¸­çš„å¸¸è§ç°è±¡")
        print("â€¢ ç¬¦åˆIEEE 754æµ®ç‚¹æ•°æ ‡å‡†")
        print()
    
    def run_complete_analysis(self):
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        print("ğŸš€ å¼€å§‹Batch-invariantå·®å¼‚åˆ†æ...\n")
        
        # 1. æµ®ç‚¹æ•°ç²¾åº¦åˆ†æ
        precision_results = self.analyze_floating_point_precision()
        
        # 2. ç´¯ç§¯é¡ºåºåˆ†æ
        accumulation_results = self.analyze_accumulation_order()
        
        # 3. epså‚æ•°åˆ†æ
        eps_results = self.analyze_eps_effect()
        
        # 4. è®¾å¤‡å·®å¼‚åˆ†æ
        self.analyze_device_differences()
        
        # 5. è§£é‡Šå·®å¼‚åŸå› 
        self.explain_why_differences_exist()
        
        print("âœ… Batch-invariantå·®å¼‚åˆ†æå®Œæˆï¼")

def main():
    """ä¸»å‡½æ•°"""
    analyzer = InvariantDifferenceAnalyzer()
    analyzer.run_complete_analysis()

if __name__ == "__main__":
    main()
