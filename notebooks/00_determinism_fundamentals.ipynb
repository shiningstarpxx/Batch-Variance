{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 00 - 确定性推理基础\n",
        "\n",
        "本notebook展示LLM推理中的确定性基础概念：\n",
        "\n",
        "1. **随机种子固定** - 确保可重现性\n",
        "2. **推理入口不变性** - 相同输入产生相同输出\n",
        "3. **温度为0时的输出概率不变性** - 确定性采样\n",
        "\n",
        "这些是理解LLM非确定性问题的前提条件。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "使用中文字体: Arial Unicode MS\n",
            "使用中文字体: Arial Unicode MS\n",
            "使用中文字体: Arial Unicode MS\n",
            "使用中文字体: Arial Unicode MS\n",
            "使用中文字体: Arial Unicode MS\n",
            "使用中文字体: Arial Unicode MS\n",
            "使用中文字体: Arial Unicode MS\n",
            "使用设备: mps\n",
            "使用Apple Silicon MPS加速\n"
          ]
        }
      ],
      "source": [
        "# 导入必要的库\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "from typing import List, Dict, Any\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# 添加src目录到路径\n",
        "sys.path.append('..')\n",
        "\n",
        "# 导入项目模块\n",
        "from src.device_manager import get_device\n",
        "from src.font_config import setup_chinese_fonts, force_chinese_fonts\n",
        "\n",
        "# 设置中文字体\n",
        "setup_chinese_fonts()\n",
        "force_chinese_fonts()\n",
        "\n",
        "# 设置设备\n",
        "device = get_device('auto')\n",
        "print(f\"使用设备: {device}\")\n",
        "if device.type == 'mps':\n",
        "    print(\"使用Apple Silicon MPS加速\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 随机种子固定演示\n",
        "\n",
        "随机种子是确保可重现性的关键。在深度学习中，多个随机源需要同时控制：\n",
        "- PyTorch的随机数生成器\n",
        "- Python的random模块\n",
        "- NumPy的随机数生成器\n",
        "- CUDA的随机数生成器（如果使用GPU）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def set_all_seeds(seed: int = 42):\n",
        "    \"\"\"设置所有随机种子\"\"\"\n",
        "    # Python随机种子\n",
        "    random.seed(seed)\n",
        "    \n",
        "    # NumPy随机种子\n",
        "    np.random.seed(seed)\n",
        "    \n",
        "    # PyTorch随机种子\n",
        "    torch.manual_seed(seed)\n",
        "    \n",
        "    # 如果使用CUDA\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    \n",
        "    # 如果使用MPS\n",
        "    if device.type == 'mps':\n",
        "        torch.mps.manual_seed(seed)\n",
        "    \n",
        "    # 确保PyTorch的确定性行为\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    \n",
        "    print(f\"所有随机种子已设置为: {seed}\")\n",
        "\n",
        "def reset_all_seeds():\n",
        "    \"\"\"重置所有随机种子\"\"\"\n",
        "    # 重置为随机状态\n",
        "    random.seed()\n",
        "    np.random.seed()\n",
        "    torch.manual_seed(torch.initial_seed())\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(torch.cuda.initial_seed())\n",
        "    \n",
        "    if device.type == 'mps':\n",
        "        # MPS没有initial_seed方法，使用随机种子\n",
        "        torch.mps.manual_seed(random.randint(0, 2**32-1))\n",
        "    \n",
        "    print(\"所有随机种子已重置为随机状态\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== 随机种子固定演示 ===\n",
            "\n",
            "1. 不固定种子（随机状态）:\n",
            "所有随机种子已重置为随机状态\n",
            "  第1次: -0.080836\n",
            "  第2次: -0.812970\n",
            "  第3次: -0.547025\n",
            "  第4次: -0.178629\n",
            "  第5次: 0.086520\n",
            "\n",
            "2. 固定种子（种子=42）:\n",
            "所有随机种子已设置为: 42\n",
            "  第1次: 0.336690\n",
            "  第2次: 0.128809\n",
            "  第3次: 0.234462\n",
            "  第4次: 0.230333\n",
            "  第5次: -1.122856\n",
            "\n",
            "3. 再次固定相同种子（种子=42）:\n",
            "所有随机种子已设置为: 42\n",
            "  第1次: 0.336690\n",
            "  第2次: 0.128809\n",
            "  第3次: 0.234462\n",
            "  第4次: 0.230333\n",
            "  第5次: -1.122856\n",
            "\n",
            "=== 可重现性验证 ===\n",
            "第2次和第3次结果相同: True\n",
            "第1次和第2次结果不同: True\n"
          ]
        }
      ],
      "source": [
        "# 演示随机种子固定的效果\n",
        "print(\"=== 随机种子固定演示 ===\")\n",
        "\n",
        "# 测试1: 不固定种子\n",
        "print(\"\\n1. 不固定种子（随机状态）:\")\n",
        "reset_all_seeds()\n",
        "random_values_1 = []\n",
        "for i in range(5):\n",
        "    val = torch.randn(1).item()\n",
        "    random_values_1.append(val)\n",
        "    print(f\"  第{i+1}次: {val:.6f}\")\n",
        "\n",
        "print(\"\\n2. 固定种子（种子=42）:\")\n",
        "set_all_seeds(42)\n",
        "random_values_2 = []\n",
        "for i in range(5):\n",
        "    val = torch.randn(1).item()\n",
        "    random_values_2.append(val)\n",
        "    print(f\"  第{i+1}次: {val:.6f}\")\n",
        "\n",
        "print(\"\\n3. 再次固定相同种子（种子=42）:\")\n",
        "set_all_seeds(42)\n",
        "random_values_3 = []\n",
        "for i in range(5):\n",
        "    val = torch.randn(1).item()\n",
        "    random_values_3.append(val)\n",
        "    print(f\"  第{i+1}次: {val:.6f}\")\n",
        "\n",
        "# 验证可重现性\n",
        "print(\"\\n=== 可重现性验证 ===\")\n",
        "print(f\"第2次和第3次结果相同: {random_values_2 == random_values_3}\")\n",
        "print(f\"第1次和第2次结果不同: {random_values_1 != random_values_2}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 推理入口不变性演示\n",
        "\n",
        "推理入口不变性是指：对于相同的输入，在固定随机种子的情况下，应该产生完全相同的输出。这是确定性推理的基本要求。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "模型已创建，参数量: 7,395,304\n"
          ]
        }
      ],
      "source": [
        "class SimpleTransformer(nn.Module):\n",
        "    \"\"\"简单的Transformer模型用于演示\"\"\"\n",
        "    \n",
        "    def __init__(self, vocab_size: int = 1000, d_model: int = 512, nhead: int = 8, \n",
        "                 num_layers: int = 2, max_len: int = 128):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_encoding = nn.Parameter(torch.randn(max_len, d_model))\n",
        "        \n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model, nhead=nhead, dim_feedforward=2048, \n",
        "            dropout=0.1, batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.output_proj = nn.Linear(d_model, vocab_size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # 输入嵌入\n",
        "        seq_len = x.size(1)\n",
        "        x = self.embedding(x) * np.sqrt(self.d_model)\n",
        "        x = x + self.pos_encoding[:seq_len].unsqueeze(0)\n",
        "        \n",
        "        # Transformer编码\n",
        "        x = self.transformer(x)\n",
        "        \n",
        "        # 输出投影\n",
        "        logits = self.output_proj(x)\n",
        "        \n",
        "        return logits\n",
        "\n",
        "# 创建模型\n",
        "model = SimpleTransformer().to(device)\n",
        "model.eval()\n",
        "\n",
        "print(f\"模型已创建，参数量: {sum(p.numel() for p in model.parameters()):,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== 推理入口不变性测试 ===\n",
            "输入序列: [[1, 5, 10, 15, 20]]\n",
            "测试次数: 5\n",
            "所有随机种子已设置为: 42\n",
            "  第1次推理完成\n",
            "所有随机种子已设置为: 42\n",
            "  第2次推理完成\n",
            "所有随机种子已设置为: 42\n",
            "  第3次推理完成\n",
            "所有随机种子已设置为: 42\n",
            "  第4次推理完成\n",
            "所有随机种子已设置为: 42\n",
            "  第5次推理完成\n",
            "  ✅ 第2次结果与第1次相同，最大差异: 0.00e+00\n",
            "  ✅ 第3次结果与第1次相同，最大差异: 0.00e+00\n",
            "  ✅ 第4次结果与第1次相同，最大差异: 0.00e+00\n",
            "  ✅ 第5次结果与第1次相同，最大差异: 0.00e+00\n",
            "\n",
            "=== 总结 ===\n",
            "所有结果相同: True\n",
            "最大差异: 0.00e+00\n"
          ]
        }
      ],
      "source": [
        "def test_inference_invariance(model, input_ids, num_trials: int = 5):\n",
        "    \"\"\"测试推理入口不变性\"\"\"\n",
        "    print(f\"\\n=== 推理入口不变性测试 ===\")\n",
        "    print(f\"输入序列: {input_ids.tolist()}\")\n",
        "    print(f\"测试次数: {num_trials}\")\n",
        "    \n",
        "    results = []\n",
        "    \n",
        "    for trial in range(num_trials):\n",
        "        # 固定种子\n",
        "        set_all_seeds(42)\n",
        "        \n",
        "        # 推理\n",
        "        with torch.no_grad():\n",
        "            output = model(input_ids)\n",
        "            # 获取最后一个token的logits\n",
        "            last_logits = output[0, -1, :].cpu().numpy()\n",
        "            results.append(last_logits)\n",
        "            \n",
        "        print(f\"  第{trial+1}次推理完成\")\n",
        "    \n",
        "    # 验证结果一致性\n",
        "    reference = results[0]\n",
        "    all_same = True\n",
        "    max_diff = 0.0\n",
        "    \n",
        "    for i, result in enumerate(results[1:], 1):\n",
        "        diff = np.max(np.abs(result - reference))\n",
        "        max_diff = max(max_diff, diff)\n",
        "        if diff > 1e-6:\n",
        "            all_same = False\n",
        "            print(f\"  ❌ 第{i+1}次结果与第1次不同，最大差异: {diff:.2e}\")\n",
        "        else:\n",
        "            print(f\"  ✅ 第{i+1}次结果与第1次相同，最大差异: {diff:.2e}\")\n",
        "    \n",
        "    print(f\"\\n=== 总结 ===\")\n",
        "    print(f\"所有结果相同: {all_same}\")\n",
        "    print(f\"最大差异: {max_diff:.2e}\")\n",
        "    \n",
        "    return all_same, max_diff\n",
        "\n",
        "# 创建测试输入\n",
        "test_input = torch.tensor([[1, 5, 10, 15, 20]], device=device)\n",
        "\n",
        "# 测试推理入口不变性\n",
        "is_invariant, max_diff = test_inference_invariance(model, test_input, num_trials=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 温度为0时的输出概率不变性\n",
        "\n",
        "在LLM推理中，温度参数控制输出的随机性：\n",
        "- 温度 = 0：确定性采样（贪婪解码）\n",
        "- 温度 > 0：随机采样，温度越高越随机\n",
        "\n",
        "当温度为0时，模型应该总是选择概率最高的token，从而产生确定性的输出。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sample_with_temperature(logits, temperature: float = 1.0, top_k: int = None, top_p: float = None):\n",
        "    \"\"\"带温度的采样函数\"\"\"\n",
        "    if temperature == 0:\n",
        "        # 贪婪解码（确定性）\n",
        "        return torch.argmax(logits, dim=-1)\n",
        "    \n",
        "    # 应用温度\n",
        "    logits = logits / temperature\n",
        "    \n",
        "    # Top-k过滤\n",
        "    if top_k is not None:\n",
        "        top_k = min(top_k, logits.size(-1))\n",
        "        indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n",
        "        logits[indices_to_remove] = float('-inf')\n",
        "    \n",
        "    # Top-p过滤\n",
        "    if top_p is not None:\n",
        "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
        "        cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "        \n",
        "        # 移除累积概率超过top_p的token\n",
        "        sorted_indices_to_remove = cumulative_probs > top_p\n",
        "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
        "        sorted_indices_to_remove[..., 0] = 0\n",
        "        \n",
        "        indices_to_remove = sorted_indices_to_remove.scatter(1, sorted_indices, sorted_indices_to_remove)\n",
        "        logits[indices_to_remove] = float('-inf')\n",
        "    \n",
        "    # 采样\n",
        "    probs = F.softmax(logits, dim=-1)\n",
        "    return torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "def test_temperature_invariance(model, input_ids, temperature: float, num_trials: int = 10):\n",
        "    \"\"\"测试温度不变性\"\"\"\n",
        "    print(f\"\\n=== 温度={temperature}时的输出不变性测试 ===\")\n",
        "    \n",
        "    results = []\n",
        "    \n",
        "    for trial in range(num_trials):\n",
        "        # 固定种子\n",
        "        set_all_seeds(42)\n",
        "        \n",
        "        # 推理\n",
        "        with torch.no_grad():\n",
        "            logits = model(input_ids)\n",
        "            last_logits = logits[0, -1, :]\n",
        "            \n",
        "            # 采样\n",
        "            next_token = sample_with_temperature(last_logits.unsqueeze(0), temperature=temperature)\n",
        "            results.append(next_token.item())\n",
        "            \n",
        "        print(f\"  第{trial+1}次采样: token_id = {results[-1]}\")\n",
        "    \n",
        "    # 分析结果\n",
        "    unique_tokens = set(results)\n",
        "    print(f\"\\n=== 分析结果 ===\")\n",
        "    print(f\"唯一token数量: {len(unique_tokens)}\")\n",
        "    print(f\"唯一tokens: {sorted(unique_tokens)}\")\n",
        "    \n",
        "    if temperature == 0:\n",
        "        is_deterministic = len(unique_tokens) == 1\n",
        "        print(f\"温度=0时是否确定性: {is_deterministic}\")\n",
        "    else:\n",
        "        print(f\"温度={temperature}时的随机性: {len(unique_tokens)}/{num_trials}\")\n",
        "    \n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== 温度对输出确定性的影响 ===\n",
            "\n",
            "=== 温度=0.0时的输出不变性测试 ===\n",
            "所有随机种子已设置为: 42\n",
            "  第1次采样: token_id = 679\n",
            "所有随机种子已设置为: 42\n",
            "  第2次采样: token_id = 679\n",
            "所有随机种子已设置为: 42\n",
            "  第3次采样: token_id = 679\n",
            "所有随机种子已设置为: 42\n",
            "  第4次采样: token_id = 679\n",
            "所有随机种子已设置为: 42\n",
            "  第5次采样: token_id = 679\n",
            "所有随机种子已设置为: 42\n",
            "  第6次采样: token_id = 679\n",
            "所有随机种子已设置为: 42\n",
            "  第7次采样: token_id = 679\n",
            "所有随机种子已设置为: 42\n",
            "  第8次采样: token_id = 679\n",
            "所有随机种子已设置为: 42\n",
            "  第9次采样: token_id = 679\n",
            "所有随机种子已设置为: 42\n",
            "  第10次采样: token_id = 679\n",
            "\n",
            "=== 分析结果 ===\n",
            "唯一token数量: 1\n",
            "唯一tokens: [679]\n",
            "温度=0时是否确定性: True\n",
            "\n",
            "=== 温度=0.5时的输出不变性测试 ===\n",
            "所有随机种子已设置为: 42\n",
            "  第1次采样: token_id = 242\n",
            "所有随机种子已设置为: 42\n",
            "  第2次采样: token_id = 242\n",
            "所有随机种子已设置为: 42\n",
            "  第3次采样: token_id = 242\n",
            "所有随机种子已设置为: 42\n",
            "  第4次采样: token_id = 242\n",
            "所有随机种子已设置为: 42\n",
            "  第5次采样: token_id = 242\n",
            "所有随机种子已设置为: 42\n",
            "  第6次采样: token_id = 242\n",
            "所有随机种子已设置为: 42\n",
            "  第7次采样: token_id = 242\n",
            "所有随机种子已设置为: 42\n",
            "  第8次采样: token_id = 242\n",
            "所有随机种子已设置为: 42\n",
            "  第9次采样: token_id = 242\n",
            "所有随机种子已设置为: 42\n",
            "  第10次采样: token_id = 242\n",
            "\n",
            "=== 分析结果 ===\n",
            "唯一token数量: 1\n",
            "唯一tokens: [242]\n",
            "温度=0.5时的随机性: 1/10\n",
            "\n",
            "=== 温度=1.0时的输出不变性测试 ===\n",
            "所有随机种子已设置为: 42\n",
            "  第1次采样: token_id = 7\n",
            "所有随机种子已设置为: 42\n",
            "  第2次采样: token_id = 7\n",
            "所有随机种子已设置为: 42\n",
            "  第3次采样: token_id = 7\n",
            "所有随机种子已设置为: 42\n",
            "  第4次采样: token_id = 7\n",
            "所有随机种子已设置为: 42\n",
            "  第5次采样: token_id = 7\n",
            "所有随机种子已设置为: 42\n",
            "  第6次采样: token_id = 7\n",
            "所有随机种子已设置为: 42\n",
            "  第7次采样: token_id = 7\n",
            "所有随机种子已设置为: 42\n",
            "  第8次采样: token_id = 7\n",
            "所有随机种子已设置为: 42\n",
            "  第9次采样: token_id = 7\n",
            "所有随机种子已设置为: 42\n",
            "  第10次采样: token_id = 7\n",
            "\n",
            "=== 分析结果 ===\n",
            "唯一token数量: 1\n",
            "唯一tokens: [7]\n",
            "温度=1.0时的随机性: 1/10\n",
            "\n",
            "=== 温度=2.0时的输出不变性测试 ===\n",
            "所有随机种子已设置为: 42\n",
            "  第1次采样: token_id = 7\n",
            "所有随机种子已设置为: 42\n",
            "  第2次采样: token_id = 7\n",
            "所有随机种子已设置为: 42\n",
            "  第3次采样: token_id = 7\n",
            "所有随机种子已设置为: 42\n",
            "  第4次采样: token_id = 7\n",
            "所有随机种子已设置为: 42\n",
            "  第5次采样: token_id = 7\n",
            "所有随机种子已设置为: 42\n",
            "  第6次采样: token_id = 7\n",
            "所有随机种子已设置为: 42\n",
            "  第7次采样: token_id = 7\n",
            "所有随机种子已设置为: 42\n",
            "  第8次采样: token_id = 7\n",
            "所有随机种子已设置为: 42\n",
            "  第9次采样: token_id = 7\n",
            "所有随机种子已设置为: 42\n",
            "  第10次采样: token_id = 7\n",
            "\n",
            "=== 分析结果 ===\n",
            "唯一token数量: 1\n",
            "唯一tokens: [7]\n",
            "温度=2.0时的随机性: 1/10\n"
          ]
        }
      ],
      "source": [
        "# 测试不同温度下的行为\n",
        "print(\"=== 温度对输出确定性的影响 ===\")\n",
        "\n",
        "# 温度 = 0（确定性）\n",
        "results_temp0 = test_temperature_invariance(model, test_input, temperature=0.0, num_trials=10)\n",
        "\n",
        "# 温度 = 0.5（低随机性）\n",
        "results_temp05 = test_temperature_invariance(model, test_input, temperature=0.5, num_trials=10)\n",
        "\n",
        "# 温度 = 1.0（标准随机性）\n",
        "results_temp1 = test_temperature_invariance(model, test_input, temperature=1.0, num_trials=10)\n",
        "\n",
        "# 温度 = 2.0（高随机性）\n",
        "results_temp2 = test_temperature_invariance(model, test_input, temperature=2.0, num_trials=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 可视化温度对输出分布的影响\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_temperature_effects(model, input_ids, temperatures: List[float] = [0.0, 0.5, 1.0, 2.0]):\n",
        "    \"\"\"可视化不同温度对输出分布的影响\"\"\"\n",
        "    print(\"\\n=== 可视化温度对输出分布的影响 ===\")\n",
        "    \n",
        "    # 获取logits\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_ids)\n",
        "        last_logits = logits[0, -1, :].cpu().numpy()\n",
        "    \n",
        "    # 创建子图\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for i, temp in enumerate(temperatures):\n",
        "        # 计算概率分布\n",
        "        if temp == 0:\n",
        "            # 温度=0时，只有最高概率的token有概率1，其他为0\n",
        "            probs = np.zeros_like(last_logits)\n",
        "            max_idx = np.argmax(last_logits)\n",
        "            probs[max_idx] = 1.0\n",
        "        else:\n",
        "            # 应用温度\n",
        "            scaled_logits = last_logits / temp\n",
        "            probs = F.softmax(torch.tensor(scaled_logits), dim=0).numpy()\n",
        "        \n",
        "        # 选择top-20 tokens进行可视化\n",
        "        top_indices = np.argsort(probs)[-20:]\n",
        "        top_probs = probs[top_indices]\n",
        "        \n",
        "        # 绘制条形图\n",
        "        axes[i].bar(range(len(top_probs)), top_probs, alpha=0.7)\n",
        "        axes[i].set_title(f'温度 = {temp}', fontsize=14, fontweight='bold')\n",
        "        axes[i].set_xlabel('Token ID (Top-20)', fontsize=12)\n",
        "        axes[i].set_ylabel('概率', fontsize=12)\n",
        "        axes[i].grid(True, alpha=0.3)\n",
        "        \n",
        "        # 添加统计信息\n",
        "        entropy = -np.sum(probs * np.log(probs + 1e-10))\n",
        "        axes[i].text(0.02, 0.98, f'熵: {entropy:.3f}', \n",
        "                    transform=axes[i].transAxes, verticalalignment='top',\n",
        "                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.suptitle('不同温度下的输出概率分布', fontsize=16, fontweight='bold', y=1.02)\n",
        "    \n",
        "    # 保存图片\n",
        "    os.makedirs('../experiments/plots', exist_ok=True)\n",
        "    plt.savefig('../experiments/plots/temperature_effects.png', dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    \n",
        "    print(\"图片已保存到: experiments/plots/temperature_effects.png\")\n",
        "\n",
        "# 可视化温度效果\n",
        "visualize_temperature_effects(model, test_input)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 综合确定性测试\n",
        "\n",
        "结合所有确定性要素，测试完整的推理流程：\n",
        "1. 固定随机种子\n",
        "2. 相同输入\n",
        "3. 温度为0\n",
        "4. 多次运行验证一致性\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def comprehensive_determinism_test(model, input_ids, num_trials: int = 10):\n",
        "    \"\"\"综合确定性测试\"\"\"\n",
        "    print(\"\\n=== 综合确定性测试 ===\")\n",
        "    print(\"测试条件:\")\n",
        "    print(\"  - 固定随机种子 (seed=42)\")\n",
        "    print(\"  - 相同输入序列\")\n",
        "    print(\"  - 温度 = 0 (贪婪解码)\")\n",
        "    print(f\"  - 测试次数: {num_trials}\")\n",
        "    \n",
        "    results = []\n",
        "    \n",
        "    for trial in range(num_trials):\n",
        "        # 1. 固定所有随机种子\n",
        "        set_all_seeds(42)\n",
        "        \n",
        "        # 2. 推理\n",
        "        with torch.no_grad():\n",
        "            logits = model(input_ids)\n",
        "            last_logits = logits[0, -1, :]\n",
        "            \n",
        "            # 3. 温度=0采样（贪婪解码）\n",
        "            next_token = sample_with_temperature(last_logits.unsqueeze(0), temperature=0.0)\n",
        "            results.append(next_token.item())\n",
        "            \n",
        "        print(f\"  第{trial+1}次: token_id = {results[-1]}\")\n",
        "    \n",
        "    # 验证结果\n",
        "    unique_tokens = set(results)\n",
        "    is_deterministic = len(unique_tokens) == 1\n",
        "    \n",
        "    print(f\"\\n=== 测试结果 ===\")\n",
        "    print(f\"唯一token数量: {len(unique_tokens)}\")\n",
        "    print(f\"唯一tokens: {sorted(unique_tokens)}\")\n",
        "    print(f\"是否完全确定性: {is_deterministic}\")\n",
        "    \n",
        "    if is_deterministic:\n",
        "        print(\"✅ 测试通过: 推理完全确定性\")\n",
        "    else:\n",
        "        print(\"❌ 测试失败: 推理存在非确定性\")\n",
        "        print(\"可能的原因:\")\n",
        "        print(\"  - 模型内部存在非确定性操作\")\n",
        "        print(\"  - 硬件层面的非确定性\")\n",
        "        print(\"  - 浮点数精度问题\")\n",
        "    \n",
        "    return is_deterministic, results\n",
        "\n",
        "# 运行综合测试\n",
        "is_deterministic, test_results = comprehensive_determinism_test(model, test_input, num_trials=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 总结\n",
        "\n",
        "本notebook展示了LLM推理中的三个关键确定性概念：\n",
        "\n",
        "### 1. 随机种子固定\n",
        "- 控制所有随机数生成器（Python、NumPy、PyTorch、CUDA/MPS）\n",
        "- 确保可重现性\n",
        "- 是确定性推理的基础\n",
        "\n",
        "### 2. 推理入口不变性\n",
        "- 相同输入 + 固定种子 = 相同输出\n",
        "- 验证模型推理的确定性\n",
        "- 检测模型内部的非确定性操作\n",
        "\n",
        "### 3. 温度为0的输出概率不变性\n",
        "- 温度=0时使用贪婪解码\n",
        "- 总是选择概率最高的token\n",
        "- 消除采样随机性\n",
        "\n",
        "### 实际应用中的挑战\n",
        "\n",
        "即使满足上述所有条件，LLM推理仍可能出现非确定性，主要原因包括：\n",
        "\n",
        "1. **浮点数非结合性** - 不同计算顺序产生不同结果\n",
        "2. **并行计算** - 多线程/多GPU执行顺序不确定\n",
        "3. **硬件差异** - 不同硬件平台的数值精度差异\n",
        "4. **优化算法** - 某些优化可能导致非确定性\n",
        "\n",
        "这些就是我们在后续notebooks中要深入探讨的问题。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 可视化温度对输出分布的影响\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
