{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 00 - 确定性推理基础\n",
        "\n",
        "本notebook展示LLM推理中的确定性基础概念：\n",
        "\n",
        "1. **随机种子固定** - 确保可重现性\n",
        "2. **推理入口不变性** - 相同输入产生相同输出\n",
        "3. **温度为0时的输出概率不变性** - 确定性采样\n",
        "\n",
        "这些是理解LLM非确定性问题的前提条件。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "使用中文字体: Arial Unicode MS\n",
            "使用中文字体: Arial Unicode MS\n",
            "使用中文字体: Arial Unicode MS\n",
            "使用中文字体: Arial Unicode MS\n",
            "使用中文字体: Arial Unicode MS\n",
            "使用中文字体: Arial Unicode MS\n",
            "使用中文字体: Arial Unicode MS\n",
            "使用设备: mps\n",
            "使用Apple Silicon MPS加速\n"
          ]
        }
      ],
      "source": [
        "# 导入必要的库\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "from typing import List, Dict, Any\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# 添加src目录到路径\n",
        "sys.path.append('..')\n",
        "\n",
        "# 导入项目模块\n",
        "from src.device_manager import get_device\n",
        "from src.font_config import setup_chinese_fonts, force_chinese_fonts\n",
        "\n",
        "# 设置中文字体\n",
        "setup_chinese_fonts()\n",
        "force_chinese_fonts()\n",
        "\n",
        "# 设置设备\n",
        "device = get_device('auto')\n",
        "print(f\"使用设备: {device}\")\n",
        "if device.type == 'mps':\n",
        "    print(\"使用Apple Silicon MPS加速\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 随机种子固定演示\n",
        "\n",
        "随机种子是确保可重现性的关键。在深度学习中，多个随机源需要同时控制：\n",
        "- PyTorch的随机数生成器\n",
        "- Python的random模块\n",
        "- NumPy的随机数生成器\n",
        "- CUDA的随机数生成器（如果使用GPU）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def set_all_seeds(seed: int = 42):\n",
        "    \"\"\"设置所有随机种子\"\"\"\n",
        "    # Python随机种子\n",
        "    random.seed(seed)\n",
        "    \n",
        "    # NumPy随机种子\n",
        "    np.random.seed(seed)\n",
        "    \n",
        "    # PyTorch随机种子\n",
        "    torch.manual_seed(seed)\n",
        "    \n",
        "    # 如果使用CUDA\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    \n",
        "    # 如果使用MPS\n",
        "    if device.type == 'mps':\n",
        "        torch.mps.manual_seed(seed)\n",
        "    \n",
        "    # 确保PyTorch的确定性行为\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    \n",
        "    print(f\"所有随机种子已设置为: {seed}\")\n",
        "\n",
        "def reset_all_seeds():\n",
        "    \"\"\"重置所有随机种子\"\"\"\n",
        "    # 重置为随机状态\n",
        "    random.seed()\n",
        "    np.random.seed()\n",
        "    torch.manual_seed(torch.initial_seed())\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(torch.cuda.initial_seed())\n",
        "    \n",
        "    if device.type == 'mps':\n",
        "        # MPS没有initial_seed方法，使用随机种子\n",
        "        torch.mps.manual_seed(random.randint(0, 2**32-1))\n",
        "    \n",
        "    print(\"所有随机种子已重置为随机状态\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== 随机种子固定演示 ===\n",
            "\n",
            "1. 不固定种子（随机状态）:\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "module 'torch.mps' has no attribute 'initial_seed'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 测试1: 不固定种子\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m1. 不固定种子（随机状态）:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mreset_all_seeds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m random_values_1 = []\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m5\u001b[39m):\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mreset_all_seeds\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     35\u001b[39m     torch.cuda.manual_seed(torch.cuda.initial_seed())\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m device.type == \u001b[33m'\u001b[39m\u001b[33mmps\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m     torch.mps.manual_seed(\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmps\u001b[49m\u001b[43m.\u001b[49m\u001b[43minitial_seed\u001b[49m())\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m所有随机种子已重置为随机状态\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mAttributeError\u001b[39m: module 'torch.mps' has no attribute 'initial_seed'"
          ]
        }
      ],
      "source": [
        "# 演示随机种子固定的效果\n",
        "print(\"=== 随机种子固定演示 ===\")\n",
        "\n",
        "# 测试1: 不固定种子\n",
        "print(\"\\n1. 不固定种子（随机状态）:\")\n",
        "reset_all_seeds()\n",
        "random_values_1 = []\n",
        "for i in range(5):\n",
        "    val = torch.randn(1).item()\n",
        "    random_values_1.append(val)\n",
        "    print(f\"  第{i+1}次: {val:.6f}\")\n",
        "\n",
        "print(\"\\n2. 固定种子（种子=42）:\")\n",
        "set_all_seeds(42)\n",
        "random_values_2 = []\n",
        "for i in range(5):\n",
        "    val = torch.randn(1).item()\n",
        "    random_values_2.append(val)\n",
        "    print(f\"  第{i+1}次: {val:.6f}\")\n",
        "\n",
        "print(\"\\n3. 再次固定相同种子（种子=42）:\")\n",
        "set_all_seeds(42)\n",
        "random_values_3 = []\n",
        "for i in range(5):\n",
        "    val = torch.randn(1).item()\n",
        "    random_values_3.append(val)\n",
        "    print(f\"  第{i+1}次: {val:.6f}\")\n",
        "\n",
        "# 验证可重现性\n",
        "print(\"\\n=== 可重现性验证 ===\")\n",
        "print(f\"第2次和第3次结果相同: {random_values_2 == random_values_3}\")\n",
        "print(f\"第1次和第2次结果不同: {random_values_1 != random_values_2}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 推理入口不变性演示\n",
        "\n",
        "推理入口不变性是指：对于相同的输入，在固定随机种子的情况下，应该产生完全相同的输出。这是确定性推理的基本要求。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleTransformer(nn.Module):\n",
        "    \"\"\"简单的Transformer模型用于演示\"\"\"\n",
        "    \n",
        "    def __init__(self, vocab_size: int = 1000, d_model: int = 512, nhead: int = 8, \n",
        "                 num_layers: int = 2, max_len: int = 128):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.pos_encoding = nn.Parameter(torch.randn(max_len, d_model))\n",
        "        \n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model, nhead=nhead, dim_feedforward=2048, \n",
        "            dropout=0.1, batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.output_proj = nn.Linear(d_model, vocab_size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # 输入嵌入\n",
        "        seq_len = x.size(1)\n",
        "        x = self.embedding(x) * np.sqrt(self.d_model)\n",
        "        x = x + self.pos_encoding[:seq_len].unsqueeze(0)\n",
        "        \n",
        "        # Transformer编码\n",
        "        x = self.transformer(x)\n",
        "        \n",
        "        # 输出投影\n",
        "        logits = self.output_proj(x)\n",
        "        \n",
        "        return logits\n",
        "\n",
        "# 创建模型\n",
        "model = SimpleTransformer().to(device)\n",
        "model.eval()\n",
        "\n",
        "print(f\"模型已创建，参数量: {sum(p.numel() for p in model.parameters()):,}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_inference_invariance(model, input_ids, num_trials: int = 5):\n",
        "    \"\"\"测试推理入口不变性\"\"\"\n",
        "    print(f\"\\n=== 推理入口不变性测试 ===\")\n",
        "    print(f\"输入序列: {input_ids.tolist()}\")\n",
        "    print(f\"测试次数: {num_trials}\")\n",
        "    \n",
        "    results = []\n",
        "    \n",
        "    for trial in range(num_trials):\n",
        "        # 固定种子\n",
        "        set_all_seeds(42)\n",
        "        \n",
        "        # 推理\n",
        "        with torch.no_grad():\n",
        "            output = model(input_ids)\n",
        "            # 获取最后一个token的logits\n",
        "            last_logits = output[0, -1, :].cpu().numpy()\n",
        "            results.append(last_logits)\n",
        "            \n",
        "        print(f\"  第{trial+1}次推理完成\")\n",
        "    \n",
        "    # 验证结果一致性\n",
        "    reference = results[0]\n",
        "    all_same = True\n",
        "    max_diff = 0.0\n",
        "    \n",
        "    for i, result in enumerate(results[1:], 1):\n",
        "        diff = np.max(np.abs(result - reference))\n",
        "        max_diff = max(max_diff, diff)\n",
        "        if diff > 1e-6:\n",
        "            all_same = False\n",
        "            print(f\"  ❌ 第{i+1}次结果与第1次不同，最大差异: {diff:.2e}\")\n",
        "        else:\n",
        "            print(f\"  ✅ 第{i+1}次结果与第1次相同，最大差异: {diff:.2e}\")\n",
        "    \n",
        "    print(f\"\\n=== 总结 ===\")\n",
        "    print(f\"所有结果相同: {all_same}\")\n",
        "    print(f\"最大差异: {max_diff:.2e}\")\n",
        "    \n",
        "    return all_same, max_diff\n",
        "\n",
        "# 创建测试输入\n",
        "test_input = torch.tensor([[1, 5, 10, 15, 20]], device=device)\n",
        "\n",
        "# 测试推理入口不变性\n",
        "is_invariant, max_diff = test_inference_invariance(model, test_input, num_trials=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 温度为0时的输出概率不变性\n",
        "\n",
        "在LLM推理中，温度参数控制输出的随机性：\n",
        "- 温度 = 0：确定性采样（贪婪解码）\n",
        "- 温度 > 0：随机采样，温度越高越随机\n",
        "\n",
        "当温度为0时，模型应该总是选择概率最高的token，从而产生确定性的输出。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def sample_with_temperature(logits, temperature: float = 1.0, top_k: int = None, top_p: float = None):\n",
        "    \"\"\"带温度的采样函数\"\"\"\n",
        "    if temperature == 0:\n",
        "        # 贪婪解码（确定性）\n",
        "        return torch.argmax(logits, dim=-1)\n",
        "    \n",
        "    # 应用温度\n",
        "    logits = logits / temperature\n",
        "    \n",
        "    # Top-k过滤\n",
        "    if top_k is not None:\n",
        "        top_k = min(top_k, logits.size(-1))\n",
        "        indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n",
        "        logits[indices_to_remove] = float('-inf')\n",
        "    \n",
        "    # Top-p过滤\n",
        "    if top_p is not None:\n",
        "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
        "        cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "        \n",
        "        # 移除累积概率超过top_p的token\n",
        "        sorted_indices_to_remove = cumulative_probs > top_p\n",
        "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
        "        sorted_indices_to_remove[..., 0] = 0\n",
        "        \n",
        "        indices_to_remove = sorted_indices_to_remove.scatter(1, sorted_indices, sorted_indices_to_remove)\n",
        "        logits[indices_to_remove] = float('-inf')\n",
        "    \n",
        "    # 采样\n",
        "    probs = F.softmax(logits, dim=-1)\n",
        "    return torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "def test_temperature_invariance(model, input_ids, temperature: float, num_trials: int = 10):\n",
        "    \"\"\"测试温度不变性\"\"\"\n",
        "    print(f\"\\n=== 温度={temperature}时的输出不变性测试 ===\")\n",
        "    \n",
        "    results = []\n",
        "    \n",
        "    for trial in range(num_trials):\n",
        "        # 固定种子\n",
        "        set_all_seeds(42)\n",
        "        \n",
        "        # 推理\n",
        "        with torch.no_grad():\n",
        "            logits = model(input_ids)\n",
        "            last_logits = logits[0, -1, :]\n",
        "            \n",
        "            # 采样\n",
        "            next_token = sample_with_temperature(last_logits.unsqueeze(0), temperature=temperature)\n",
        "            results.append(next_token.item())\n",
        "            \n",
        "        print(f\"  第{trial+1}次采样: token_id = {results[-1]}\")\n",
        "    \n",
        "    # 分析结果\n",
        "    unique_tokens = set(results)\n",
        "    print(f\"\\n=== 分析结果 ===\")\n",
        "    print(f\"唯一token数量: {len(unique_tokens)}\")\n",
        "    print(f\"唯一tokens: {sorted(unique_tokens)}\")\n",
        "    \n",
        "    if temperature == 0:\n",
        "        is_deterministic = len(unique_tokens) == 1\n",
        "        print(f\"温度=0时是否确定性: {is_deterministic}\")\n",
        "    else:\n",
        "        print(f\"温度={temperature}时的随机性: {len(unique_tokens)}/{num_trials}\")\n",
        "    \n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 测试不同温度下的行为\n",
        "print(\"=== 温度对输出确定性的影响 ===\")\n",
        "\n",
        "# 温度 = 0（确定性）\n",
        "results_temp0 = test_temperature_invariance(model, test_input, temperature=0.0, num_trials=10)\n",
        "\n",
        "# 温度 = 0.5（低随机性）\n",
        "results_temp05 = test_temperature_invariance(model, test_input, temperature=0.5, num_trials=10)\n",
        "\n",
        "# 温度 = 1.0（标准随机性）\n",
        "results_temp1 = test_temperature_invariance(model, test_input, temperature=1.0, num_trials=10)\n",
        "\n",
        "# 温度 = 2.0（高随机性）\n",
        "results_temp2 = test_temperature_invariance(model, test_input, temperature=2.0, num_trials=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 可视化温度对输出分布的影响\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
